{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import textblob\n",
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('DataScientest_07_OCR_docs/Data Images to Text/800 image to text.csv', usecols=[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sysousg szaaay - 83dplixy — o99fqo}, dyaqg 387...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>milton w. white, m.d.. f.1.0.5. 1439 east cute...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xenobiotica, 1990, vor. 20, no. 12, 1353-1356 ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\" “ww mes hl $8 sod ced jo ywayuod aujootu pur...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lorillard,  memorandum  march 5, 1997  to: w. ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  sysousg szaaay - 83dplixy — o99fqo}, dyaqg 387...     14\n",
       "1  milton w. white, m.d.. f.1.0.5. 1439 east cute...      6\n",
       "2  xenobiotica, 1990, vor. 20, no. 12, 1353-1356 ...      9\n",
       "3  \" “ww mes hl $8 sod ced jo ywayuod aujootu pur...      3\n",
       "4  lorillard,  memorandum  march 5, 1997  to: w. ...      7"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from spellchecker import SpellChecker\n",
    "spell = SpellChecker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrected(text):\n",
    "    y = ''\n",
    "    if pd.isna(text):\n",
    "        y = 'nan'\n",
    "    y = str(text).lower()\n",
    "    y = re.sub(r'[^a-z]+', ' ', y)\n",
    "    y = y.strip()\n",
    "    return y\n",
    "\n",
    "def correct_ocr_text(text):\n",
    "    corrected_text = []\n",
    "    text = corrected(text)\n",
    "    if text != 'nan':\n",
    "        text = TextBlob(text).correct()\n",
    "        text = str(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "# tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINISHED (SAVED IN corrected)\n",
    "\n",
    "# tqdm.pandas()\n",
    "# df['ctext']= df['text'].progress_apply(lambda x: correct_ocr_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = pd.read_csv('DataScientest_07_OCR_docs/Data Images to Text/800 image to text - corrected.csv', usecols=range(1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>ctext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>: woe memorandum se te anarican ibeoer cnypang...</td>\n",
       "      <td>7</td>\n",
       "      <td>woe memorandum se te american beer cnypang mr ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>albert einstein college o! medicine of yeshiva...</td>\n",
       "      <td>0</td>\n",
       "      <td>albert einstein college o medicine of yeshiva ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2062410152 z6gt'et loquiaydag sonvua antva sho...</td>\n",
       "      <td>4</td>\n",
       "      <td>z it et loquiaydag sonya anna show now stands ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>v. b.e.8.8 54  2 groot-bugaarden “1 hotveld 24...</td>\n",
       "      <td>3</td>\n",
       "      <td>v b e groom bugaarden hotel fax faktuur fractu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>ctr acknowledged  ©. b. cohen  chapter 3 |  pu...</td>\n",
       "      <td>8</td>\n",
       "      <td>car acknowledged b cohens chapter pulmonary en...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label   \n",
       "697  : woe memorandum se te anarican ibeoer cnypang...      7  \\\n",
       "693  albert einstein college o! medicine of yeshiva...      0   \n",
       "118  2062410152 z6gt'et loquiaydag sonvua antva sho...      4   \n",
       "546  v. b.e.8.8 54  2 groot-bugaarden “1 hotveld 24...      3   \n",
       "590  ctr acknowledged  ©. b. cohen  chapter 3 |  pu...      8   \n",
       "\n",
       "                                                 ctext  \n",
       "697  woe memorandum se te american beer cnypang mr ...  \n",
       "693  albert einstein college o medicine of yeshiva ...  \n",
       "118  z it et loquiaydag sonya anna show now stands ...  \n",
       "546  v b e groom bugaarden hotel fax faktuur fractu...  \n",
       "590  car acknowledged b cohens chapter pulmonary en...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfc.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sysousg szaaay - 83dplixy — o99fqo}, dyaqg 3879 - oly © suoday *  ',\n",
       "  'sysousg szaaay dplixy o fro dying only sunday',\n",
       "  14),\n",
       " ('milton w. white, m.d.. f.1.0.5. 1439 east cuter drive detroit; micm. aua34,  2. twinenoox 23-2400 ‘ree, senria88,  degrees wayne university college of medicine 1938  fellow international college of surgeons 1960 fellow american society of abdominal surgeons 1960 wayne county medical society  michigan medical society  american medical society  member american medical writers association  list of publications  power of self knowledge; published by the julian press 1957, reprinted 1969  be “the benign peptic ulcer,, the need for a more critical analysis\" reprinted from the journal of the michigan state medical society, volume 57, paged 573 - 578, april, 1958  > journal of 35, no. 1,  \"tissue factors and resistance to carcinoma the international college of surgeons, vol january 1961  “benign gastric ena duodenal ulcer, a multi-complex disorder\" reprinted from the journal of the michigan state medical society, volume 60, pages 1312 - 1318, october, 1961.  “the etiology and pathogenesis of carcinoma, leukemia, possibly of hodgkins, determined by results found in revised culturing procedures\", 1963 by milton w. white, m.d.  \"etiology of malignancies, a new concept\" from the department of research, north detroit general hospital, february 19, 1965. journal of the international college of surgeons, vol. 43, no. 6, june 1965  “increasing evidence that the \"transformed\" yeast or mola micro-organism is the etiological factor behind the patho- genesis of cancerous tissue\" director of the department of research, international surgery, vol. 48, no. 5, nov. 1967  50576191  ',\n",
       "  'milton w white m d f east outer drive detroit mice au twinenoox see hernia degrees wayne university college of medicine fellow international college of surgeons fellow american society of abdominal surgeons wayne county medical society michigan medical society american medical society member american medical writers association list of publications power of self knowledge published by the julian press reprinted be the benign septic ulcer the need for a more critical analysis reprinted from the journal of the michigan state medical society volume page april journal of no tissue factors and resistance to carcinoma the international college of surgeons vol january benign gastric end duodenal ulcer a multi complex disorder reprinted from the journal of the michigan state medical society volume pages october the etiology and pathogenesis of carcinoma leukaemia possibly of hodgkin determined by results found in revised capturing procedures by milton w white m d etiology of malignancies a new concept from the department of research north detroit general hospital february journal of the international college of surgeons vol no june increasing evidence that the transformed least or mole micro organism is the etiological factor behind the path genesis of cancerous tissue director of the department of research international surgery vol no nov',\n",
       "  6),\n",
       " (\"xenobiotica, 1990, vor. 20, no. 12, 1353-1356  identification of cis-3’-hydroxycotinine as a urinary nicotine metabolite  p. voncken, k. rustemeier and'g. schepers:  inbifo institut fur biologische forschung, fuggerstrasse 3, 1d-5000 koln 90, frg  received 2 january 1990, accepted’ 30 june 1990  1. cir-3'-hydroxycotinine was detected as an s{—)-nicatine metabolite in the urine of smokers as well as in the urine of rats and hamsters dosed sith sco  2. ‘the excreted amount of ct-3'-hydroxycotinineis lower than that of the trans-isomer  introduction hydroxycotinine, a nicotine metabolite, was isolated three decades ago fromthe urine of dogs (mckennis et al. 1959), rats (mckennis ef al. 1962), and humans (bowman and mckennis 1962) dosed with nicotine or cotinine. ‘the exact structure and stereoconformation of metabolic hydroxycotinine was established by dagne and castagnoli (1972) to be trans-3'-hydroxycotinine, howeves recently that trans-3'-hydroxycotinine was recognized/as a major nicotine metabolite inthe urine of smokers (neurath ef al. 1987, jacob et ai. 1988) as well as in the wu: nd rabbits following iip. nicotine admin:  of guinea pigs, syrian hamsters, (nwosurand crooks 1988). ‘the presence of cis-3’-hydroxycotinine as a urinary nicotine metabolite has not been reported to date, although o”doherty ef af. (1988) analysed the urine of a smoker for the presence of the cis-isomer but did not detect it, probably due to the detection limit of their h.p.le. method. using capillary glc.-mass spectrometry and h.p.lic., we were able to separate and identify cis-3'-hydroxycotinine as an s(—)-nicotine metabolite in the u rats and/hamsters dosed with nicotine, as well as in the urine of smokers.  materials and methods ‘is and trans-3'-hydroxycotinine were obtained from the institut flr biopharmazcutische mikro- analytik, (g. newrath (hamburg, frg). for gl-c-musss spectrometric analyaes sas chromatograph  ry colurnn (30m = 025 men; j8w carla erba, frg) was directly coupled to the son source gonization voltage 0¢v). for the hip-le, ses based on the method described by barlow etal. (1987)a liquid chromatograph (hewlett-packard, modelit090m1) and a nova-pak c18 columa (15 cm x 3-7 mm; millipore. frg) were used. as the mobile phase, sodium pentane sulphonate in phosphoric acidland the solvents methanol, tetrahydrofuran, and acetonitrile with a ternary gradient were used. uv. detection was performed at s32 nm. full detaiteot the gic. and hypil.e. method sill be reported elsewhere  following the i.v- administration of 0-8 mg s(—)-nicotineike body weight to male sprague—dawl fats and 2-5mg st )-nicotnefkg body weight to male syrian hameters, urive samples were callected fer 28h. from smokers with a daily consumption of o5-2 ciparette packs, random carmpies of urine were token. extraction of the urine samples for g-l.. analyses was performed as described for the sirmaltancosts determination af trans-3'-hydroxyeotinine with nicotine and cotinine (voncken ef af. 1989)  (02049-8254/90 $3.00 6 1990 talon & f  os9eg6sz02 \",\n",
       "  'xenobiotica for no identification of his hydroxycotinine as a urinary nicotine metabolism p voncken k rustemeier and g schemes indigo institute fur biologische forschung fuggerstrasse d on fig received january accepted june air hydroxycotinine was detected as an s nicatine metabolism in the urine of smokers as well as in the urine of rats and masters doses with so the excited amount of it hydroxycotinineis lower than that of the trans some introduction hydroxycotinine a nicotine metabolism was isolated three decades ago frothy urine of dogs mckennis et al rats mckennis of al and humans woman and mckennis doses with nicotine or cotinine the exact structure and stereoconformation of metallic hydroxycotinine was established by dane and castagnoli to be trans hydroxycotinine however recently that trans hydroxycotinine was recognized as a major nicotine metabolism the urine of smokers neurath of al jacob et ai as well as in the we nd rabbits following iii nicotine admit of guinea pigs syrian masters nwosurand brooks the presence of his hydroxycotinine as a urinary nicotine metabolism has not been reported to date although o poverty of of analyzed the urine of a smoker for the presence of the his some but did not detect it probably due to the detection limit of their h p le method using capillary all mass spectrometry and h p lie we were able to separate and identify his hydroxycotinine as an s nicotine metabolism in the u rats and masters doses with nicotine as well as in the urine of smokers materials and methods is and trans hydroxycotinine were obtained from the institute for biopharmazcutische micro analysis g wrath hamburg fig for go c muss spectrometric analysis was chromatograph by column m men j w carl era fig was directly coupled to the son source gonization voltage v for the hip le ses based on the method described by barlow metal a liquid chromatograph hewlett packed modest m and a nova pay c column cm x mm millipore fig were used as the mobile phase sodium dentine sulphate in phosphorus acidland the solvents methanol tetrahydrofuran and acetonitrile with a tertiary radiant were used up detection was performed at s nm full detaiteot the gin and pupil e method sill be reported elsewhere following the i v administration of my s nicotineike body weight to male prague dawn fats and my st nicotnefkg body weight to male syrian hatters drive samples were collected for h from smokers with a daily consumption of o cigarette packs random armies of urine were token extraction of the urine samples for g l analysis was performed as described for the sirmaltancosts determination of trans hydroxyeotinine with nicotine and cotinine voncken of of salon f os eg s',\n",
       "  9)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfc = dfc[['text', 'ctext', 'label']]\n",
    "# display(dfc.sample(5))\n",
    "tuples = [tuple(i) for i in dfc.to_numpy()]\n",
    "tuples[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def tokenize_text(text):\n",
    "    return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "def remove_stop_words(tokens):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    return [token for token in tokens if token not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "\n",
    "def lemmatize_tokens(tokens):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "\n",
    "def stemming_tokens(tokens):\n",
    "    ps = PorterStemmer()\n",
    "    return [ps.stem(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_letter_tokens(tokens):\n",
    "    return [token for token in tokens if len(token) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import words\n",
    "# nltk.download('words')\n",
    "\n",
    "english_words = set(words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def english_text(tokens):\n",
    "    english_words = set(words.words())\n",
    "    tokens = [word for word in tokens if word in english_words]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    try:\n",
    "        tokens = tokenize_text(text)\n",
    "        tokens = english_text(tokens)\n",
    "        tokens = remove_stop_words(tokens)\n",
    "        tokens = lemmatize_tokens(tokens)\n",
    "    #     tokens = stemming_tokens(tokens)\n",
    "        tokens = min_letter_tokens(tokens)\n",
    "        sentence = ' '.join(tokens)\n",
    "    except:\n",
    "        sentence = ''\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def process_tuples(tuples_input):\n",
    "    return tuples_input[0], tuples_input[1], preprocess_text(tuples_input[1]), tuples_input[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"lorillard,  memorandum  march 5, 1997  to: w. r. deaton from: s. r. benson re: product test panel results: salem lights 85's (1003-97)  attached are the lotar menthol product test panel results for salem lights 85's.  background the lotar menthol segment slipped 1% in the 12 months ending december 1996 and now accounts for 10.15% of the market. all major lotar menthol 85's brands reported lower share in 1996 except marlboro menthol lights 85's which showed strong growth off a small base. newport lights 85's kept pace with the market, declining 1%, whilethe segment leader, salem lights 85's reported a 4% decline.  rationale for product evaluation  salem lights 85's were previously tested in february 1996. as part of routine competitive product monitoring, the product was tested again in january 1997 to determine if there have been any changes in consumer acceptance of the brand. in addition, this brand style is the action standard to which ‘newport lights 85's cigarettes is compared.  products reviewed  update salem lights 85's will be compared to the previous test of the brand (2/96) as well as to key competitors in the segment, newport lights 85's (4/96) and marlboro menthol lights 85's (5/95). product specifications are outlined below. although the tar count is higher for update salem lights 85's than for the previous product, r&d confirms that this difference is within the normal range of variability and does not necessarily represent a product reformulation.  date tar nic. menthol tested brand ct. ong.) lev. (mg) level % 297 update salem lights 85's 10.3 0.77 623 2196 previous salem lights 85's 8.6 0.73 gat 4196 ‘newport lights 85's 8.4 0.68 457  s195 marlboro menthol lights 85's 10.1 0.78 558.  64042598  \",\n",
       " 'lorillard memorandum march to w r deacon from s r benton re product test panel results salem lights s attached are the later menthol product test panel results for salem lights s background the later menthol segment slipped in the months ending december and now accounts for of the market all major later menthol s bands reported lower share in except marlboro menthol lights s which showed strong growth off a small base newport lights s kept pace with the market declining whilethe segment leader salem lights s reported a decline rational for product evaluation salem lights s were previously tested in february as part of routine competitive product monitoring the product was tested again in january to determine if there have been any changes in consumer acceptance of the brand in addition this brand style is the action standard to which newport lights s cigarettes is compared products reviewed update salem lights s will be compared to the previous test of the brand as well as to key competitors in the segment newport lights s and marlboro menthol lights s product specification are outlined below although the tar count is higher for update salem lights s than for the previous product r d confirms that this difference is within the normal range of amiability and does not necessarily represent a product reformation date tar nice menthol tested brand it ong let my level update salem lights s previous salem lights s at newport lights s s marlboro menthol lights s',\n",
       " 7)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuples[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"lorillard,  memorandum  march 5, 1997  to: w. r. deaton from: s. r. benson re: product test panel results: salem lights 85's (1003-97)  attached are the lotar menthol product test panel results for salem lights 85's.  background the lotar menthol segment slipped 1% in the 12 months ending december 1996 and now accounts for 10.15% of the market. all major lotar menthol 85's brands reported lower share in 1996 except marlboro menthol lights 85's which showed strong growth off a small base. newport lights 85's kept pace with the market, declining 1%, whilethe segment leader, salem lights 85's reported a 4% decline.  rationale for product evaluation  salem lights 85's were previously tested in february 1996. as part of routine competitive product monitoring, the product was tested again in january 1997 to determine if there have been any changes in consumer acceptance of the brand. in addition, this brand style is the action standard to which ‘newport lights 85's cigarettes is compared.  products reviewed  update salem lights 85's will be compared to the previous test of the brand (2/96) as well as to key competitors in the segment, newport lights 85's (4/96) and marlboro menthol lights 85's (5/95). product specifications are outlined below. although the tar count is higher for update salem lights 85's than for the previous product, r&d confirms that this difference is within the normal range of variability and does not necessarily represent a product reformulation.  date tar nic. menthol tested brand ct. ong.) lev. (mg) level % 297 update salem lights 85's 10.3 0.77 623 2196 previous salem lights 85's 8.6 0.73 gat 4196 ‘newport lights 85's 8.4 0.68 457  s195 marlboro menthol lights 85's 10.1 0.78 558.  64042598  \",\n",
       " 'lorillard memorandum march to w r deacon from s r benton re product test panel results salem lights s attached are the later menthol product test panel results for salem lights s background the later menthol segment slipped in the months ending december and now accounts for of the market all major later menthol s bands reported lower share in except marlboro menthol lights s which showed strong growth off a small base newport lights s kept pace with the market declining whilethe segment leader salem lights s reported a decline rational for product evaluation salem lights s were previously tested in february as part of routine competitive product monitoring the product was tested again in january to determine if there have been any changes in consumer acceptance of the brand in addition this brand style is the action standard to which newport lights s cigarettes is compared products reviewed update salem lights s will be compared to the previous test of the brand as well as to key competitors in the segment newport lights s and marlboro menthol lights s product specification are outlined below although the tar count is higher for update salem lights s than for the previous product r d confirms that this difference is within the normal range of amiability and does not necessarily represent a product reformation date tar nice menthol tested brand it ong let my level update salem lights s previous salem lights s at newport lights s s marlboro menthol lights s',\n",
       " 'memorandum march deacon product test panel attached later menthol product test panel background later menthol segment slipped ending market major later menthol lower share except menthol strong growth small base kept pace market segment leader decline rational product evaluation previously tested part routine competitive product product tested determine consumer acceptance brand addition brand style action standard update previous test brand well key segment menthol product specification outlined although tar count higher update previous product difference within normal range amiability necessarily represent product reformation date tar nice menthol tested brand let level update previous menthol',\n",
       " 7)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_tuples(tuples[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuple no 13 is error\n",
      "Tuple no 20 is error\n",
      "Tuple no 34 is error\n",
      "Tuple no 36 is error\n",
      "Tuple no 57 is error\n",
      "Tuple no 83 is error\n",
      "Tuple no 98 is error\n",
      "Tuple no 110 is error\n",
      "Tuple no 151 is error\n",
      "Tuple no 160 is error\n",
      "Tuple no 174 is error\n",
      "Tuple no 180 is error\n",
      "Tuple no 215 is error\n",
      "Tuple no 241 is error\n",
      "Tuple no 262 is error\n",
      "Tuple no 271 is error\n",
      "Tuple no 301 is error\n",
      "Tuple no 307 is error\n",
      "Tuple no 311 is error\n",
      "Tuple no 331 is error\n",
      "Tuple no 335 is error\n",
      "Tuple no 341 is error\n",
      "Tuple no 344 is error\n",
      "Tuple no 358 is error\n",
      "Tuple no 370 is error\n",
      "Tuple no 372 is error\n",
      "Tuple no 388 is error\n",
      "Tuple no 437 is error\n",
      "Tuple no 455 is error\n",
      "Tuple no 467 is error\n",
      "Tuple no 477 is error\n",
      "Tuple no 479 is error\n",
      "Tuple no 487 is error\n",
      "Tuple no 511 is error\n",
      "Tuple no 523 is error\n",
      "Tuple no 528 is error\n",
      "Tuple no 545 is error\n",
      "Tuple no 570 is error\n",
      "Tuple no 572 is error\n",
      "Tuple no 625 is error\n",
      "Tuple no 641 is error\n",
      "Tuple no 653 is error\n",
      "Tuple no 660 is error\n",
      "Tuple no 669 is error\n",
      "Tuple no 706 is error\n",
      "Tuple no 768 is error\n",
      "Tuple no 770 is error\n",
      "Tuple no 771 is error\n",
      "Tuple no 781 is error\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "out = []\n",
    "for i, tupl in enumerate(tuples):\n",
    "    out_tuple = process_tuples(tupl)\n",
    "    if out_tuple[2] == '':\n",
    "        print('Tuple no {} is error'.format(i))\n",
    "    out.append(out_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(nan, nan, '', 10)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[570]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('c. h. mullen feel the spirit of american\" keynote adoress  t. a. albert — brief introduction  thank you terry . . . and thank all of you . . . and i mean all of you for what you have helped enable our company to achieve. these achievements were especially important in 1990 as that was our centennial year . . . and the fact that our company has survived and prospered for over a hundred years is, in of itself, a remarkable achievement .  which you helped make possible.  yes, appreciation and recognition for your achievement . . . and also the contribution of your sales representatives . . . district sales representatives and part-time sales personnel are central to the theme of my remarks . . . which i promise will be brief, but hopefully, meaningful.  actually, the theme of my remarks is about themes! we have had plenty of them over the past few years, haven\\'t we? remember when our revitalization began back in 1986 . . . the theme was \"you and the new american tobacco company\" . . . then came \"breakthrough \\'87\" followed by \"the race is on\" . . . and then came \"winning the american way\" and last year the theme was “achievement through challenge.\" you might wonder, what was the purpose of these themes? what made them \"good\" themes?  and, i think we can agree, they were good . . . very good themes . .  but why? :  ',\n",
       " 'c h sullen feel the spirit of american denote address t a albert brief introduction thank you merry and thank all of you and i mean all of you for what you have helped enable our company to achieve these achievements were especially important in as that was our centennial year and the fact that our company has survived and prosper for over a hundred years is in of itself a remarkable achievement which you helped make possible yes appreciation and recognition for your achievement and also the contribution of your sales representatives district sales representatives and part time sales personnel are central to the theme of my remarks which i promise will be brief but hopefully meaningful actually the theme of my remarks is about themes we have had plenty of them over the past few years haven t we remember when our revitalization began back in the theme was you and the new american tobacco company then came breakthrough followed by the race is on and then came winning the american way and last year the theme was achievement through challenge you might wonder what was the purpose of these themes what made them good themes and i think we can agree they were good very good themes but why',\n",
       " 'sullen feel spirit denote address brief introduction thank merry thank mean enable company achieve especially important centennial year fact company prosper hundred remarkable achievement make possible yes appreciation recognition achievement also contribution district part time personnel central theme promise brief hopefully meaningful actually theme plenty past remember revitalization back theme new tobacco company came breakthrough race came winning way last year theme achievement challenge might wonder purpose made good think agree good good',\n",
       " 1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[772]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fro dying', 'white east outer drive mouse see hernia university college medicine fellow international college fellow society abdominal county medical society michigan medical society medical society member medical association list power self knowledge press benign septic ulcer need critical analysis journal michigan state medical society volume page journal tissue resistance carcinoma international college vol benign gastric end duodenal ulcer complex disorder journal michigan state medical society volume etiology pathogenesis carcinoma possibly determined found white etiology new concept department research north general hospital journal international college vol june increasing evidence least mole micro organism etiological factor behind path genesis cancerous tissue director department research international surgery vol', 'identification urinary nicotine metabolism indigo institute fur fig received accepted june air metabolism urine well urine excited amount lower introduction nicotine metabolism isolated three ago frothy urine dog woman nicotine exact structure metallic established however recently major nicotine metabolism urine well following nicotine admit guinea presence urinary nicotine metabolism date although poverty urine smoker presence detect probably due detection limit method capillary mass spectrometry lie able separate identify nicotine metabolism nicotine well urine institute micro analysis wrath fig mus spectrometric analysis chromatograph column men carl era fig directly coupled son source voltage hip based method barlow metal liquid chromatograph modest nova pay column fig used mobile phase sodium dentine sulphate phosphorus acetonitrile tertiary radiant used detection full gin pupil method sill elsewhere following administration body weight male dawn body weight male drive collected daily consumption cigarette random urine token extraction urine analysis determination nicotine salon', 'red seat idiot set may sue fig serious nine cry alone salt aye data gray way sign say away anna apart ten varied serious age ana pose one case pin pour may put per serious end ending soda seen data see met bay gape axiom row spun say stop anus angry used synod cava lay area ran would sail', 'memorandum march deacon product test panel attached later menthol product test panel background later menthol segment slipped ending market major later menthol lower share except menthol strong growth small base kept pace market segment leader decline rational product evaluation previously tested part routine competitive product product tested determine consumer acceptance brand addition brand style action standard update previous test brand well key segment menthol product specification outlined although tar count higher update previous product difference within normal range amiability necessarily represent product reformation date tar nice menthol tested brand let level update previous menthol']\n"
     ]
    }
   ],
   "source": [
    "sentences = [x[2] for x in out]\n",
    "print(sentences[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CountVectorizer object and fit it to the sentences\n",
    "count_vectorizer = TfidfVectorizer()\n",
    "count_vectorizer.fit(sentences)\n",
    "\n",
    "# Transform the sentences into a bag of words\n",
    "bag_of_words = count_vectorizer.fit_transform(sentences)\n",
    "\n",
    "\n",
    "# Create a TfidfVectorizer object and fit it to the sentences\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectorizer.fit(sentences)\n",
    "\n",
    "# Transform the sentences into a bag of words\n",
    "tfidf_words = tfidf_vectorizer.fit_transform(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 6941)\n"
     ]
    }
   ],
   "source": [
    "bag_of_words\n",
    "print(bag_of_words.get_shape())\n",
    "# feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14, 6]\n"
     ]
    }
   ],
   "source": [
    "target = [x[-1] for x in out]\n",
    "# target = np.argmax(target, axis=1)\n",
    "print(target[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aback' 'abandoned' 'abate' ... 'zip' 'zone' 'zoology']\n",
      "['aback' 'abandoned' 'abate' ... 'zip' 'zone' 'zoology']\n"
     ]
    }
   ],
   "source": [
    "print(count_vectorizer.get_feature_names_out())\n",
    "print(tfidf_vectorizer.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE, Isomap\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "isomap = Isomap(n_neighbors=50, n_components=2)\n",
    "iso_matrix = isomap.fit_transform(tfidf_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# multi_rf_clf = MultiOutputClassifier(rf, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tfidf_words\n",
    "y = target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=10)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score = 96.79%\n",
      "Test score = 29.17%\n"
     ]
    }
   ],
   "source": [
    "print('Train score = {:.2%}'.format(rf.score(X_train, y_train)))\n",
    "print('Test score = {:.2%}'.format(rf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "# Convert text data to TF-IDF vectors\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vector = tfidf_vectorizer.fit_transform(preprocessed_text_list)\n",
    "\n",
    "# Convert sparse matrix to dense matrix\n",
    "X = tfidf_vector.toarray()\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert training and testing sets to TensorFlow Keras inputs\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "\n",
    "# Define the TensorFlow Keras model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_dim=X.shape[1]),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_dataset.batch(batch_size),\n",
    "          epochs=num_epochs,\n",
    "          validation_data=test_dataset.batch(batch_size))\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(test_dataset.batch(batch_size))\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input, Dense\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
